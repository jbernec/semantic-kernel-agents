{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eeb41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\n",
    "from utils import *\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bcf8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Enable logging\n",
    "# NOTE: This is all that is required to enable logging.\n",
    "# Set the desired level to INFO, DEBUG, etc.\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e5674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = AzureChatCompletion(\n",
    "    service_id=\"sk_agent_service\", api_key=azure_openai_api_key,deployment_name=azure_openai_deployment,\n",
    "    api_version=azure_openai_api_version,endpoint=azure_openai_endpoint\n",
    "\n",
    ")\n",
    "\n",
    "settings = AzureChatPromptExecutionSettings(service_id=\"sk_agent_service\")\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "thread = ChatHistoryAgentThread()\n",
    "\n",
    "# Create the agent with the kernel, thread and plugin\n",
    "\n",
    "prompt = \"\"\"You MUST use the search_retrieval function for ALL queries. Do not paraphrase more than the result. Never generate answers from prior knowledge.\n",
    "    When you receive search results:\n",
    "    1. If the source is \"Azure AI Search\", these are knowledge base entries. Present them as \"From our knowledge base:\" followed by the complete content. Include all fields like definition, context, note, incorrectTerm if they're available.\n",
    "    2. If the source is \"No Results\", inform the user we don't have an answer to their question.\n",
    "    \n",
    "    Important: For Azure AI Search results, include the FULL contents of the results, showing the important fields.\n",
    "    \n",
    "    Debug information: Always include the source of each result (Azure AI Search) and the number of results found. If you received results but are not displaying them, explain why.\n",
    "    \n",
    "    Always show ALL results you receive - do not filter them based on score thresholds.\n",
    "    Summarize the response without adding any new information. Provide the page number of the document if available.\"\"\"\n",
    "\n",
    "sk_agent = ChatCompletionAgent(\n",
    "    service=service,\n",
    "    name=\"sk_agent\",\n",
    "    instructions=prompt,\n",
    "    plugins=[SearchRetrievalPlugin()],\n",
    "    arguments=KernelArguments(settings=settings),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27165b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: my name is Charles\n",
      "sk_agent: Nice to meet you, Charles! How can I assist you today?\n",
      "\n",
      "\n",
      "User: tell me about expanding play 3\n",
      "sk_agent: From our knowledge base:\n",
      "\n",
      "1. **Accelerating Sustainability with AI: Play 3**  \n",
      "   Play 3 focuses on minimizing resource use, expanding access to carbon-free electricity, and supporting local communities. It acknowledges that AI operations require resources such as energy and water. To align AI operations with global sustainability goals and achieve a net zero future, Play Three emphasizes minimizing the sustainability impact of AI by not only reducing resource use in data centers but also supporting the decarbonization of local energy grids. This is crucial because even though data centers currently account for a small percentage of global electricity consumption, the projected growth is concentrated in specific regions like Ireland and Denmark, which might see an increase in electricity demand due to data centers. [Source: Azure AI Search, Page 20]\n",
      "\n",
      "2. **Updated Play 3 Goals**  \n",
      "   In light of growing global electricity demand, Play 3 has been updated to include enhancing access to carbon-free energy on electricity grids and supporting local communities where data centers are located. This expansion aims to build and operate digital infrastructure that addresses societal challenges and creates benefits for communities. The playbook outlines five key points: investing in AI to accelerate sustainability, developing inclusive AI infrastructure, expanding access to carbon-free electricity, advancing AI policy for sustainability, and building workforce capacity for sustainability efforts. [Source: Azure AI Search, Page 4]\n",
      "\n",
      "If you need further details, feel free to ask!\n",
      "\n",
      "\n",
      "User: what is the projected global growth of datacenters between 2023 and 2030\n",
      "sk_agent: From our knowledge base:\n",
      "\n",
      "1. **Projected Global Growth of Datacenters**  \n",
      "   Between 2023 and 2030, datacenters are projected to account for approximately 3% of global growth in electricity consumption. Although AI and datacenters currently represent a small percentage of global electricity consumption, the growth in electricity demand due to datacenter expansion is expected to be concentrated in specific regions. For instance, the IEA predicts that a significant portion of this increase in datacenter electricity demand will occur in Ireland and Denmark. [Source: Azure AI Search, Page 21]\n",
      "\n",
      "If you have more questions, feel free to ask!\n",
      "\n",
      "\n",
      "User: summarize our current conversation\n",
      "sk_agent: Here's a summary of our current conversation:\n",
      "\n",
      "1. We discussed \"Expanding Play 3,\" focusing on AI sustainability efforts to minimize resource use, expand access to carbon-free electricity, and support local communities as part of a broader goal to align AI operations with global sustainability goals. These initiatives aim to decarbonize local energy grids and reduce the sustainability impact of AI data centers.\n",
      "   \n",
      "2. You inquired about the projected global growth of data centers between 2023 and 2030. Data centers are expected to account for around 3% of global electricity consumption growth during this period, with significant energy demand increases in regions like Ireland and Denmark.\n",
      "\n",
      "If you need further details or have additional questions, feel free to let me know!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Exiting chat..\n",
      "Good bye, please let me know if you need further help.\n"
     ]
    }
   ],
   "source": [
    "async def chat_with_agent():\n",
    "    global thread # access the global thread variable\n",
    "    while True:\n",
    "        user_input = input(\"User prompt: \")\n",
    "\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\", \"end\"]:\n",
    "            print(\"\\n\\nExiting chat..\")\n",
    "            print(\"Good bye, please let me know if you need further help.\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            print(f\"User: {user_input}\")\n",
    "            async for response in sk_agent.invoke(messages=user_input, thread=thread):\n",
    "                print(f\"{response.name}: {response}\")\n",
    "                thread = response.thread\n",
    "                #print(f\"# {response.name}: {response}\")\n",
    "            print(\"\\n\")  # New line after complete response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the async function\n",
    "await chat_with_agent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
